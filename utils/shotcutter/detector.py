"""
TransNetV2é•œå¤´æ£€æµ‹å™¨

åŸºäºæ·±åº¦å­¦ä¹ çš„é•œå¤´è¾¹ç•Œæ£€æµ‹ç®—æ³•ï¼Œæ”¯æŒæ‰¹å¤„ç†å’Œæµå¼å¤„ç†æ¨¡å¼ã€‚

ä¾èµ–ï¼š
- transnetv2
- opencv-python
- numpy
"""

import cv2
import numpy as np
import os
from typing import List, Optional
from dataclasses import dataclass


@dataclass
class Shot:
    """é•œå¤´ä¿¡æ¯æ•°æ®ç±»"""
    start_frame: int     # èµ·å§‹å¸§å·
    end_frame: int       # ç»“æŸå¸§å·
    start_time: float    # èµ·å§‹æ—¶é—´(ç§’)
    end_time: float      # ç»“æŸæ—¶é—´(ç§’)
    duration: float      # é•œå¤´æ—¶é•¿(ç§’)


class TransNetDetector:
    """TransNetV2é•œå¤´æ£€æµ‹å™¨å°è£…"""

    def __init__(self, model_dir: str = None, streaming: bool = False, device: str = 'auto'):
        """
        åˆå§‹åŒ–æ£€æµ‹å™¨

        Args:
            model_dir: TransNetV2æ¨¡å‹ç›®å½•è·¯å¾„(å¯é€‰ï¼Œè‡ªåŠ¨æŸ¥æ‰¾)
            streaming: æ˜¯å¦ä½¿ç”¨æµå¼å¤„ç†æ¨¡å¼
            device: è®¾å¤‡ç±»å‹('auto'/'cuda'/'cpu')
        """
        if model_dir is None:
            model_dir = self._find_model_directory()

        self.model_dir = model_dir
        self.streaming = streaming
        self.device = device
        self._model = None
        # å»¶è¿Ÿæ£€æŸ¥æ¨¡å‹ï¼Œä¸åœ¨åˆå§‹åŒ–æ—¶æ‰“å°è­¦å‘Š

    def _find_model_directory(self) -> str:
        """è‡ªåŠ¨æŸ¥æ‰¾TransNetV2æ¨¡å‹ç›®å½•"""
        possible_paths = [
            "./models/transnetv2",
            "../models/transnetv2",
            "../../models/transnetv2",
            "/home/yong/project/videoFen/models/transnetv2",
            os.path.expanduser("~/transnetv2_weights"),
            # å°è¯•ä½¿ç”¨pipå®‰è£…çš„åŒ…
            os.path.expanduser("~/.transnetv2")
        ]

        for path in possible_paths:
            if os.path.exists(path):
                return path

        # å¦‚æœéƒ½æ‰¾ä¸åˆ°ï¼Œè¿”å›é»˜è®¤è·¯å¾„
        return "./models/transnetv2"

    def detect_shots(self, video_path: str) -> List[Shot]:
        """
        æ£€æµ‹è§†é¢‘ä¸­çš„é•œå¤´è¾¹ç•Œ

        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„

        Returns:
            List[Shot]: é•œå¤´åˆ—è¡¨

        Raises:
            FileNotFoundError: è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨
            RuntimeError: æ¨¡å‹åŠ è½½æˆ–å¤„ç†å¤±è´¥
        """
        # æ£€æŸ¥è§†é¢‘æ–‡ä»¶
        if not os.path.exists(video_path):
            raise FileNotFoundError(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")

        # åŠ è½½æ¨¡å‹
        model = self._get_model()

        try:
            if self.streaming:
                return self._detect_streaming(video_path, model)
            else:
                return self._detect_batch(video_path, model)
        except Exception as e:
            raise RuntimeError(f"é•œå¤´æ£€æµ‹å¤„ç†å¤±è´¥: {str(e)}")

    def _get_model(self):
        """å»¶è¿ŸåŠ è½½TransNetV2æ¨¡å‹"""
        if self._model is None:
            # 1. ä¼˜å…ˆå°è¯•ä½¿ç”¨æœ¬åœ°çš„PyTorchå®ç°
            if self._try_local_pytorch():
                return self._model

            # 2. å°è¯•å®‰è£…çš„ transnetv2 åŒ…
            try:
                from transnetv2 import TransNetV2
                self._model = TransNetV2(model_dir=self.model_dir)
                print(f"âœ… TransNetV2æ¨¡å‹åŠ è½½æˆåŠŸ: {self.model_dir}")
                return self._model
            except ImportError:
                pass
            except Exception:
                pass

            # 3. å°è¯•ä½¿ç”¨æœ¬åœ°å¤åˆ¶çš„æƒé‡
            if self._try_local_weights():
                return self._model

            # 4. æ‰€æœ‰æ–¹å¼éƒ½å¤±è´¥ï¼Œæ‰“å°å¸®åŠ©ä¿¡æ¯
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥")
            print(f"ğŸ’¡ è¯·ä» https://github.com/soCzech/TransNetV2 ä¸‹è½½æ¨¡å‹æ–‡ä»¶")
            print(f"ğŸ’¡ æˆ–ä½¿ç”¨ pip install transnetv2-pytorch å®‰è£…é¢„ç¼–è¯‘åŒ…")
            raise ImportError("æ— æ³•åŠ è½½TransNetV2æ¨¡å‹ï¼Œè¯·æ£€æŸ¥å®‰è£…")

        return self._model

    def _try_local_pytorch(self):
        """å°è¯•ä½¿ç”¨æœ¬åœ°PyTorchå®ç°"""
        try:
            import sys
            import os
            import torch

            # ç¡®å®šè®¾å¤‡ç±»å‹
            if self.device == 'auto':
                if torch.cuda.is_available():
                    device = 'cuda'
                    gpu_name = torch.cuda.get_device_name(0)
                    gpu_count = torch.cuda.device_count()
                    print(f"ğŸš€ æ£€æµ‹åˆ°CUDA: {gpu_count}ä¸ªGPUè®¾å¤‡")
                    print(f"ğŸ¯ ä¸»GPU: {gpu_name}")
                    print(f"âš¡ ä½¿ç”¨GPUåŠ é€Ÿå¤„ç†")
                else:
                    device = 'cpu'
                    cpu_count = os.cpu_count()
                    print(f"ğŸ’» æœªæ£€æµ‹åˆ°CUDAï¼Œä½¿ç”¨CPUå¤„ç†")
                    print(f"ğŸ”¢ CPUæ ¸å¿ƒæ•°: {cpu_count}")
                    print(f"âš ï¸  å¤„ç†é€Ÿåº¦å¯èƒ½è¾ƒæ…¢ï¼Œå»ºè®®åœ¨æœ‰GPUçš„ç¯å¢ƒä¸‹è¿è¡Œ")
            else:
                device = self.device
                if device == 'cuda':
                    print(f"ğŸš€ å¼ºåˆ¶ä½¿ç”¨CUDAè®¾å¤‡")
                elif device == 'cpu':
                    print(f"ğŸ’» å¼ºåˆ¶ä½¿ç”¨CPUè®¾å¤‡")
                else:
                    print(f"ğŸ”§ ä½¿ç”¨æŒ‡å®šè®¾å¤‡: {device}")

            # æ·»åŠ æœ¬åœ°æ¨¡å‹è·¯å¾„
            model_path = os.path.join(os.path.dirname(__file__), 'models')
            sys.path.insert(0, model_path)

            from transnetv2_pytorch import TransNetV2
            self._model = TransNetV2(device=device)  # ä¼ é€’è®¾å¤‡å‚æ•°
            print(f"âœ… ä½¿ç”¨æœ¬åœ°PyTorchæ¨¡å‹: {device.upper()}è®¾å¤‡")
            return True

        except Exception as e:
            print(f"âš ï¸  æœ¬åœ°PyTorchæ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
            return False

    def _try_local_weights(self):
        """å°è¯•ä½¿ç”¨æœ¬åœ°æƒé‡æ–‡ä»¶"""
        try:
            weights_file = os.path.join(os.path.dirname(__file__), 'models', 'transnetv2-pytorch-weights.pth')

            if os.path.exists(weights_file):
                print(f"âœ… æ‰¾åˆ°æœ¬åœ°æƒé‡æ–‡ä»¶: {weights_file}")
                # è¿™é‡Œéœ€è¦å®ç°ä¸€ä¸ªç®€å•çš„æƒé‡åŠ è½½å™¨
                print("ğŸ’¡ è¯·å®‰è£… transnetv2-pytorch æ¥ä½¿ç”¨æ­¤æƒé‡æ–‡ä»¶")
                return False
            else:
                return False

        except Exception:
            return False

    def _detect_batch(self, video_path: str, model) -> List[Shot]:
        """
        æ‰¹å¤„ç†æ¨¡å¼æ£€æµ‹é•œå¤´

        é€‚åˆå°æ–‡ä»¶ï¼Œä¸€æ¬¡æ€§å¤„ç†æ‰€æœ‰å¸§
        """
        print(f"ğŸ¬ å¼€å§‹æ‰¹å¤„ç†æ¨¡å¼æ£€æµ‹: {video_path}")

        # 1. ä½¿ç”¨TransNetV2é¢„æµ‹
        video_frames, single_frame_predictions, _ = \
            model.predict_video(video_path)

        # 2. è·å–é•œå¤´è¾¹ç•Œ (æœ¬åœ°å®ç°çš„API)
        scenes = model.predictions_to_scenes(single_frame_predictions)

        # 3. è·å–è§†é¢‘å±æ€§
        cap = cv2.VideoCapture(video_path)
        fps = cap.get(cv2.CAP_PROP_FPS)
        cap.release()

        # 4. è½¬æ¢ä¸ºShotå¯¹è±¡
        shots = []
        for start_frame, end_frame in scenes:
            start_time = start_frame / fps
            end_time = end_frame / fps
            duration = end_time - start_time

            shot = Shot(
                start_frame=start_frame,
                end_frame=end_frame,
                start_time=start_time,
                end_time=end_time,
                duration=duration
            )
            shots.append(shot)

        print(f"âœ… æ‰¹å¤„ç†æ£€æµ‹å®Œæˆï¼Œå‘ç° {len(shots)} ä¸ªé•œå¤´")
        return shots

    def _detect_streaming(self, video_path: str, model, batch_size: int = 100) -> List[Shot]:
        """
        æµå¼å¤„ç†æ¨¡å¼æ£€æµ‹é•œå¤´

        é€‚åˆå¤§æ–‡ä»¶ï¼Œåˆ†æ‰¹å¤„ç†ä»¥èŠ‚çœå†…å­˜
        """
        print(f"ğŸ¬ å¼€å§‹æµå¼æ¨¡å¼æ£€æµ‹: {video_path} (æ‰¹æ¬¡å¤§å°: {batch_size})")

        # 1. æ‰“å¼€è§†é¢‘æµ
        cap = cv2.VideoCapture(video_path)
        fps = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

        print(f"ğŸ“¹ è§†é¢‘ä¿¡æ¯: {total_frames}å¸§, {fps:.2f}fps, {total_frames/fps:.1f}ç§’")

        # 2. æµå¼å¤„ç†å˜é‡
        frame_buffer = []
        predictions = []
        shot_boundaries = []
        frame_idx = 0

        # 3. é€å¸§è¯»å–å’Œå¤„ç†
        while True:
            ret, frame = cap.read()
            if not ret:
                break

            # é¢„å¤„ç†å¸§ï¼ˆresizeåˆ°27x48ï¼‰
            processed_frame = cv2.resize(frame, (48, 27))
            frame_buffer.append(processed_frame)

            # ç´¯ç§¯åˆ°batch_sizeæ—¶è¿›è¡Œé¢„æµ‹
            if len(frame_buffer) == batch_size or frame_idx == total_frames - 1:
                # æ‰¹é‡é¢„æµ‹
                batch_frames = np.array(frame_buffer)
                batch_predictions = model.predict_frames(batch_frames)[0]  # å•å¸§é¢„æµ‹

                predictions.extend(batch_predictions.tolist())

                # æ£€æµ‹é•œå¤´è¾¹ç•Œ
                for i, pred in enumerate(batch_predictions):
                    if pred > 0.5:  # é•œå¤´è¾¹ç•Œé˜ˆå€¼
                        boundary_frame = frame_idx - len(batch_predictions) + i + 1
                        if boundary_frame > 0:
                            shot_boundaries.append(boundary_frame)

                # æ¸…ç©ºç¼“å†²åŒº
                frame_buffer = []

                # æ˜¾ç¤ºè¿›åº¦
                if frame_idx % 1000 == 0:
                    progress = (frame_idx / total_frames) * 100
                    print(f"â³ å¤„ç†è¿›åº¦: {progress:.1f}% ({frame_idx}/{total_frames})")

            frame_idx += 1

        # 4. æ„å»ºé•œå¤´åˆ—è¡¨
        shots = self._build_shots_from_boundaries(shot_boundaries, fps, total_frames)

        cap.release()
        print(f"âœ… æµå¼æ£€æµ‹å®Œæˆï¼Œå‘ç° {len(shots)} ä¸ªé•œå¤´")
        return shots

    def _build_shots_from_boundaries(self, boundaries: List[int], fps: float, total_frames: int) -> List[Shot]:
        """ä»é•œå¤´è¾¹ç•Œæ„å»ºé•œå¤´åˆ—è¡¨"""
        shots = []

        if not boundaries:
            # æ²¡æœ‰æ£€æµ‹åˆ°é•œå¤´è¾¹ç•Œï¼Œæ•´ä¸ªè§†é¢‘ä½œä¸ºä¸€ä¸ªé•œå¤´
            shots.append(Shot(
                start_frame=0,
                end_frame=total_frames - 1,
                start_time=0.0,
                end_time=(total_frames - 1) / fps,
                duration=(total_frames - 1) / fps
            ))
            return shots

        # ç¬¬ä¸€ä¸ªé•œå¤´ï¼šä»å¼€å§‹åˆ°ç¬¬ä¸€ä¸ªè¾¹ç•Œ
        start_frame = 0
        for boundary_frame in boundaries:
            end_frame = boundary_frame

            shot = Shot(
                start_frame=start_frame,
                end_frame=end_frame,
                start_time=start_frame / fps,
                end_time=end_frame / fps,
                duration=(end_frame - start_frame) / fps
            )
            shots.append(shot)
            start_frame = end_frame

        # æœ€åä¸€ä¸ªé•œå¤´ï¼šä»æœ€åä¸€ä¸ªè¾¹ç•Œåˆ°è§†é¢‘ç»“æŸ
        if start_frame < total_frames:
            shot = Shot(
                start_frame=start_frame,
                end_frame=total_frames - 1,
                start_time=start_frame / fps,
                end_time=(total_frames - 1) / fps,
                duration=(total_frames - 1 - start_frame) / fps
            )
            shots.append(shot)

        return shots