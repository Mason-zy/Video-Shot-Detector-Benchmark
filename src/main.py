#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é•œå¤´åˆ†å‰²ç®—æ³•å¯¹æ¯”å·¥å…·ä¸»ç¨‹åº
Main Entry Point for Shot Boundary Detection Comparison Tool

ä½œè€…: Assistant
æ—¥æœŸ: 2024-11-25
"""

import argparse
import sys
import os
import time
from typing import Dict, List, Any, Optional

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from shot_detector import ShotBoundary
from pyscene_detector import PySceneDetector
from ffmpeg_detector import FFmpegDetector
from transnet_detector import TransNetV2Detector
from output_manager import OutputManager


class ShotComparisonApp:
    """é•œå¤´åˆ†å‰²å¯¹æ¯”åº”ç”¨ä¸»ç±»"""

    def __init__(self, config: Dict[str, Any]):
        """
        åˆå§‹åŒ–åº”ç”¨

        Args:
            config: é…ç½®å‚æ•°
        """
        self.config = config
        self.video_path = config['video_path']
        self.output_manager = OutputManager(config.get('output_dir', 'output'))
        self.enabled_algorithms = config.get('algorithms', ['pyscene', 'ffmpeg', 'transnet'])

        print("ğŸ¬ é•œå¤´åˆ†å‰²ç®—æ³•å¯¹æ¯”å·¥å…·")
        print("=" * 50)
        print(f"ğŸ“¹ è¾“å…¥è§†é¢‘: {self.video_path}")
        print(f"ğŸ”§ å¯ç”¨çš„ç®—æ³•: {', '.join(self.enabled_algorithms)}")
        print("=" * 50)

    def validate_video_file(self) -> bool:
        """
        éªŒè¯è§†é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”å¯è¯»

        Returns:
            bool: éªŒè¯ç»“æœ
        """
        if not os.path.exists(self.video_path):
            print(f"âŒ è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {self.video_path}")
            return False

        if not os.access(self.video_path, os.R_OK):
            print(f"âŒ æ— æ³•è¯»å–è§†é¢‘æ–‡ä»¶: {self.video_path}")
            return False

        # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
        video_extensions = ['.mp4', '.avi', '.mov', '.mkv', '.flv', '.wmv', '.webm']
        file_ext = os.path.splitext(self.video_path)[1].lower()
        if file_ext not in video_extensions:
            print(f"âš ï¸  è­¦å‘Š: ä¸å¸¸è§çš„è§†é¢‘æ ¼å¼ {file_ext}ï¼Œå¯èƒ½æ— æ³•æ­£å¸¸å¤„ç†")

        return True

    def run_algorithm(self, algorithm_name: str) -> Dict[str, Any]:
        """
        è¿è¡ŒæŒ‡å®šçš„é•œå¤´åˆ†å‰²ç®—æ³•

        Args:
            algorithm_name: ç®—æ³•åç§°

        Returns:
            Dict[str, Any]: ç®—æ³•è¿è¡Œç»“æœ
        """
        print(f"\nğŸš€ å¼€å§‹è¿è¡Œ {algorithm_name.upper()} ç®—æ³•...")
        print("-" * 40)

        start_time = time.time()
        result = {
            'algorithm': algorithm_name,
            'shot_count': 0,
            'processing_time': 0,
            'extracted_files': 0,
            'shots': [],
            'notes': ''
        }

        try:
            # åˆ›å»ºæ£€æµ‹å™¨å®ä¾‹
            detector = self._create_detector(algorithm_name)
            if detector is None:
                return result

            # æ£€æµ‹é•œå¤´è¾¹ç•Œ
            shots = detector.detect_shots()
            result['shots'] = shots
            result['shot_count'] = len(shots)

            if not shots:
                result['notes'] = 'æœªæ£€æµ‹åˆ°ä»»ä½•é•œå¤´'
                return result

            # æå–é•œå¤´ç‰‡æ®µ
            output_dir = self.output_manager.get_algorithm_output_dir(algorithm_name)
            extracted_files = detector.extract_shots(shots, output_dir)
            result['extracted_files'] = len(extracted_files)

            # æ·»åŠ ç®—æ³•ä¿¡æ¯
            result['algorithm_info'] = detector.get_algorithm_info()

            # è®¡ç®—æ€»æ—¶é•¿
            total_duration = sum(shot.duration for shot in shots)
            result['total_duration'] = total_duration

            processing_time = time.time() - start_time
            result['processing_time'] = processing_time

            print(f"âœ… {algorithm_name.upper()} å®Œæˆ!")
            print(f"   æ£€æµ‹é•œå¤´æ•°: {len(shots)}")
            print(f"   æå–æ–‡ä»¶æ•°: {len(extracted_files)}")
            print(f"   å¤„ç†æ—¶é—´: {processing_time:.2f}ç§’")

        except Exception as e:
            result['notes'] = f'é”™è¯¯: {str(e)}'
            print(f"âŒ {algorithm_name.upper()} è¿è¡Œå¤±è´¥: {e}")

        return result

    def _create_detector(self, algorithm_name: str):
        """
        åˆ›å»ºæ£€æµ‹å™¨å®ä¾‹

        Args:
            algorithm_name: ç®—æ³•åç§°

        Returns:
            æ£€æµ‹å™¨å®ä¾‹æˆ–None
        """
        try:
            if algorithm_name.lower() == 'pyscene':
                return PySceneDetector(
                    self.video_path,
                    threshold=self.config.get('pyscene_threshold', 27.0),
                    min_scene_len=self.config.get('pyscene_min_scene_len', 15)
                )
            elif algorithm_name.lower() == 'ffmpeg':
                return FFmpegDetector(
                    self.video_path,
                    threshold=self.config.get('ffmpeg_threshold', 0.3),
                    min_scene_len=self.config.get('ffmpeg_min_scene_len', 1.0)
                )
            elif algorithm_name.lower() == 'transnet':
                return TransNetV2Detector(
                    self.video_path,
                    model_dir=self.config.get('transnet_model_dir', './models/transnetv2')
                )
            else:
                print(f"âŒ ä¸æ”¯æŒçš„ç®—æ³•: {algorithm_name}")
                return None

        except ImportError as e:
            print(f"âŒ {algorithm_name} ä¾èµ–åº“ç¼ºå¤±: {e}")
            return None
        except Exception as e:
            print(f"âŒ åˆ›å»º {algorithm_name} æ£€æµ‹å™¨å¤±è´¥: {e}")
            return None

    def run_all_algorithms(self) -> Dict[str, Dict[str, Any]]:
        """
        è¿è¡Œæ‰€æœ‰å¯ç”¨çš„ç®—æ³•

        Returns:
            Dict[str, Dict[str, Any]]: æ‰€æœ‰ç®—æ³•çš„ç»“æœ
        """
        results = {}

        for algorithm in self.enabled_algorithms:
            result = self.run_algorithm(algorithm)
            results[algorithm] = result

            # å¦‚æœè®¾ç½®äº†åªè¿è¡Œç¬¬ä¸€ä¸ªæˆåŠŸçš„ç®—æ³•ï¼Œåˆ™æå‰é€€å‡º
            if self.config.get('run_first_only', False) and result['shot_count'] > 0:
                print(f"âœ¨ åªè¿è¡Œç¬¬ä¸€ä¸ªæˆåŠŸç®—æ³•: {algorithm}")
                break

        return results

    def generate_reports(self, results: Dict[str, Dict[str, Any]]):
        """
        ç”Ÿæˆæ‰€æœ‰æŠ¥å‘Š

        Args:
            results: ç®—æ³•ç»“æœ
        """
        print(f"\nğŸ“Š ç”Ÿæˆåˆ†ææŠ¥å‘Š...")
        print("=" * 40)

        # è·å–è§†é¢‘ä¿¡æ¯
        video_info = {
            'video_path': self.video_path,
            **self._get_video_info()
        }

        # ç”ŸæˆåŸºæœ¬æŠ¥å‘Š
        self.output_manager.save_basic_report(results)

        # ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
        self.output_manager.save_detailed_report(results, video_info)

        # ç”Ÿæˆåˆ†ææ‘˜è¦
        summary = self.output_manager.generate_summary_analysis(results)

        # æ‰“å°æ‘˜è¦
        print("\n" + summary)

    def _get_video_info(self) -> Dict[str, Any]:
        """
        è·å–è§†é¢‘åŸºæœ¬ä¿¡æ¯

        Returns:
            Dict[str, Any]: è§†é¢‘ä¿¡æ¯
        """
        try:
            # ä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨çš„æ£€æµ‹å™¨è·å–è§†é¢‘ä¿¡æ¯
            for algorithm in ['pyscene', 'ffmpeg', 'transnet']:
                if algorithm in self.enabled_algorithms:
                    detector = self._create_detector(algorithm)
                    if detector:
                        return detector.video_info
            return {}
        except Exception:
            return {}

    def run(self):
        """è¿è¡Œä¸»ç¨‹åº"""
        try:
            # éªŒè¯è§†é¢‘æ–‡ä»¶
            if not self.validate_video_file():
                return 1

            # æ˜¾ç¤ºè¾“å‡ºç›®å½•ç»“æ„
            self.output_manager.print_directory_structure()

            # è¿è¡Œç®—æ³•
            results = self.run_all_algorithms()

            if not results:
                print("âŒ æ²¡æœ‰ç®—æ³•æˆåŠŸè¿è¡Œ")
                return 1

            # ç”ŸæˆæŠ¥å‘Š
            self.generate_reports(results)

            print(f"\nğŸ‰ ä»»åŠ¡å®Œæˆ! ç»“æœä¿å­˜åœ¨: {self.output_manager.main_output_dir}")
            return 0

        except KeyboardInterrupt:
            print("\nâ¹ï¸  ç”¨æˆ·ä¸­æ–­æ“ä½œ")
            return 1
        except Exception as e:
            print(f"\nâŒ ç¨‹åºè¿è¡Œå‡ºé”™: {e}")
            return 1


def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description='é•œå¤´åˆ†å‰²ç®—æ³•å¯¹æ¯”å·¥å…· - å¯¹æ¯” PySceneDetect, FFmpeg, TransNet V2 çš„æ•ˆæœ',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  python main.py input_video.mp4                    # è¿è¡Œæ‰€æœ‰ç®—æ³•
  python main.py input_video.mp4 -a pyscene ffmpeg  # åªè¿è¡ŒæŒ‡å®šç®—æ³•
  python main.py input_video.mp4 --pyscene-threshold 30.0  # è°ƒæ•´å‚æ•°
  python main.py input_video.mp4 --output-dir my_results  # æŒ‡å®šè¾“å‡ºç›®å½•

ç®—æ³•è¯´æ˜:
  pyscene   - PySceneDetect (åŸºäº OpenCV çš„ä¼ ç»Ÿç®—æ³•)
  ffmpeg    - FFmpeg (åŸºäº select æ»¤é•œçš„åœºæ™¯æ£€æµ‹)
  transnet  - TransNet V2 (åŸºäºæ·±åº¦å­¦ä¹ çš„ SOTA æ¨¡å‹)
        """
    )

    # å¿…éœ€å‚æ•°
    parser.add_argument('video_path', help='è¾“å…¥è§†é¢‘æ–‡ä»¶è·¯å¾„')

    # å¯é€‰å‚æ•°
    parser.add_argument('-a', '--algorithms', nargs='+',
                        choices=['pyscene', 'ffmpeg', 'transnet'],
                        default=['pyscene', 'ffmpeg', 'transnet'],
                        help='é€‰æ‹©è¦è¿è¡Œçš„ç®—æ³• (é»˜è®¤: å…¨éƒ¨)')

    parser.add_argument('-o', '--output-dir', default='output',
                        help='è¾“å‡ºç›®å½• (é»˜è®¤: output)')

    parser.add_argument('--first-only', action='store_true',
                        help='åªè¿è¡Œç¬¬ä¸€ä¸ªæˆåŠŸçš„ç®—æ³•')

    # PySceneDetect å‚æ•°
    parser.add_argument('--pyscene-threshold', type=float, default=27.0,
                        help='PySceneDetect å†…å®¹å˜åŒ–é˜ˆå€¼ (é»˜è®¤: 27.0)')

    parser.add_argument('--pyscene-min-scene-len', type=int, default=15,
                        help='PySceneDetect æœ€å°é•œå¤´é•¿åº¦(å¸§) (é»˜è®¤: 15)')

    # FFmpeg å‚æ•°
    parser.add_argument('--ffmpeg-threshold', type=float, default=0.3,
                        help='FFmpeg åœºæ™¯å˜åŒ–é˜ˆå€¼ (é»˜è®¤: 0.3)')

    parser.add_argument('--ffmpeg-min-scene-len', type=float, default=1.0,
                        help='FFmpeg æœ€å°é•œå¤´é•¿åº¦(ç§’) (é»˜è®¤: 1.0)')

    # TransNet V2 å‚æ•°
    parser.add_argument('--transnet-model-dir', default='./models/transnetv2',
                        help='TransNet V2 æ¨¡å‹ç›®å½• (é»˜è®¤: ./models/transnetv2)')

    return parser.parse_args()


def main():
    """ä¸»å‡½æ•°"""
    args = parse_arguments()

    # æ„å»ºé…ç½®
    config = {
        'video_path': args.video_path,
        'output_dir': args.output_dir,
        'algorithms': args.algorithms,
        'run_first_only': args.first_only,
        'pyscene_threshold': args.pyscene_threshold,
        'pyscene_min_scene_len': args.pyscene_min_scene_len,
        'ffmpeg_threshold': args.ffmpeg_threshold,
        'ffmpeg_min_scene_len': args.ffmpeg_min_scene_len,
        'transnet_model_dir': args.transnet_model_dir
    }

    # åˆ›å»ºå¹¶è¿è¡Œåº”ç”¨
    app = ShotComparisonApp(config)
    return app.run()


if __name__ == "__main__":
    sys.exit(main())