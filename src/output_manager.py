#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è¾“å‡ºç®¡ç†å™¨
Output Manager for Shot Detection Results

ç®¡ç†é•œå¤´åˆ†å‰²ç»“æœçš„è¾“å‡ºã€æŠ¥å‘Šç”Ÿæˆå’Œæ–‡ä»¶ç»„ç»‡
"""

import os
import csv
import json
import time
from datetime import datetime
from typing import Dict, List, Any
from pathlib import Path

from shot_detector import ShotBoundary


class OutputManager:
    """è¾“å‡ºç»“æœç®¡ç†å™¨"""

    def __init__(self, base_output_dir: str = "output"):
        """
        åˆå§‹åŒ–è¾“å‡ºç®¡ç†å™¨

        Args:
            base_output_dir: åŸºç¡€è¾“å‡ºç›®å½•
        """
        self.base_output_dir = base_output_dir
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.main_output_dir = None
        self.report_path = None
        self.detailed_report_path = None
        self._create_output_structure()

    def _create_output_structure(self):
        """åˆ›å»ºè¾“å‡ºç›®å½•ç»“æ„"""
        # åˆ›å»ºä¸»è¾“å‡ºç›®å½•
        self.main_output_dir = os.path.join(
            self.base_output_dir,
            f"shot_comparison_{self.timestamp}"
        )
        os.makedirs(self.main_output_dir, exist_ok=True)

        # åˆ›å»ºå„ç®—æ³•çš„å­ç›®å½•
        algorithm_dirs = ['pyscene', 'ffmpeg', 'transnet']
        for algo_dir in algorithm_dirs:
            os.makedirs(
                os.path.join(self.main_output_dir, algo_dir),
                exist_ok=True
            )

        # è®¾ç½®æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
        self.report_path = os.path.join(self.main_output_dir, "report.csv")
        self.detailed_report_path = os.path.join(self.main_output_dir, "detailed_report.json")

        print(f"ğŸ“ è¾“å‡ºç›®å½•å·²åˆ›å»º: {self.main_output_dir}")

    def get_algorithm_output_dir(self, algorithm_name: str) -> str:
        """
        è·å–æŒ‡å®šç®—æ³•çš„è¾“å‡ºç›®å½•

        Args:
            algorithm_name: ç®—æ³•åç§° ('pyscene', 'ffmpeg', 'transnet')

        Returns:
            str: ç®—æ³•è¾“å‡ºç›®å½•è·¯å¾„
        """
        algo_dirs = {
            'pyscene': 'pyscene',
            'ffmpeg': 'ffmpeg',
            'transnet': 'transnet'
        }

        if algorithm_name.lower() not in algo_dirs:
            raise ValueError(f"ä¸æ”¯æŒçš„ç®—æ³•: {algorithm_name}")

        return os.path.join(self.main_output_dir, algo_dirs[algorithm_name.lower()])

    def save_basic_report(self, results: Dict[str, Dict[str, Any]]):
        """
        ä¿å­˜åŸºæœ¬å¯¹æ¯”æŠ¥å‘Š (CSVæ ¼å¼)

        Args:
            results: å„ç®—æ³•çš„ç»“æœæ•°æ®
        """
        print("ğŸ“Š ç”ŸæˆåŸºæœ¬å¯¹æ¯”æŠ¥å‘Š...")

        with open(self.report_path, 'w', newline='', encoding='utf-8') as csvfile:
            fieldnames = [
                'ç®—æ³•',
                'æ£€æµ‹åˆ°çš„é•œå¤´æ•°é‡',
                'å¤„ç†æ—¶é—´(ç§’)',
                'å¹³å‡é•œå¤´æ—¶é•¿(ç§’)',
                'æœ€çŸ­é•œå¤´æ—¶é•¿(ç§’)',
                'æœ€é•¿é•œå¤´æ—¶é•¿(ç§’)',
                'æå–æ–‡ä»¶æ•°',
                'æˆåŠŸç‡(%)',
                'å¤‡æ³¨'
            ]
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            writer.writeheader()

            for algorithm, data in results.items():
                # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
                shot_count = data.get('shot_count', 0)
                processing_time = data.get('processing_time', 0)
                extracted_files = data.get('extracted_files', 0)

                # è®¡ç®—å¹³å‡ã€æœ€çŸ­ã€æœ€é•¿é•œå¤´æ—¶é•¿
                avg_duration = 0
                min_duration = 0
                max_duration = 0

                if 'shots' in data and len(data['shots']) > 0:
                    durations = [shot.duration for shot in data['shots']]
                    avg_duration = sum(durations) / len(durations)
                    min_duration = min(durations)
                    max_duration = max(durations)

                # è®¡ç®—æˆåŠŸç‡
                success_rate = (extracted_files / shot_count * 100) if shot_count > 0 else 0

                writer.writerow({
                    'ç®—æ³•': algorithm,
                    'æ£€æµ‹åˆ°çš„é•œå¤´æ•°é‡': shot_count,
                    'å¤„ç†æ—¶é—´(ç§’)': f"{processing_time:.2f}",
                    'å¹³å‡é•œå¤´æ—¶é•¿(ç§’)': f"{avg_duration:.2f}",
                    'æœ€çŸ­é•œå¤´æ—¶é•¿(ç§’)': f"{min_duration:.2f}",
                    'æœ€é•¿é•œå¤´æ—¶é•¿(ç§’)': f"{max_duration:.2f}",
                    'æå–æ–‡ä»¶æ•°': extracted_files,
                    'æˆåŠŸç‡(%)': f"{success_rate:.1f}",
                    'å¤‡æ³¨': data.get('notes', '')
                })

        print(f"âœ… åŸºæœ¬æŠ¥å‘Šå·²ä¿å­˜: {self.report_path}")

    def save_detailed_report(self, results: Dict[str, Dict[str, Any]], video_info: Dict):
        """
        ä¿å­˜è¯¦ç»†æŠ¥å‘Š (JSONæ ¼å¼)

        Args:
            results: å„ç®—æ³•çš„ç»“æœæ•°æ®
            video_info: è§†é¢‘ä¿¡æ¯
        """
        print("ğŸ“‹ ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š...")

        detailed_data = {
            'metadata': {
                'timestamp': self.timestamp,
                'video_path': video_info.get('video_path', 'Unknown'),
                'video_info': {
                    'duration': video_info.get('duration', 0),
                    'fps': video_info.get('fps', 0),
                    'frame_count': video_info.get('frame_count', 0),
                    'resolution': f"{video_info.get('width', 0)}x{video_info.get('height', 0)}"
                },
                'total_processing_time': sum(
                    data.get('processing_time', 0) for data in results.values()
                )
            },
            'algorithms': {}
        }

        # ä¸ºæ¯ä¸ªç®—æ³•æ·»åŠ è¯¦ç»†ä¿¡æ¯
        for algorithm, data in results.items():
            algo_data = {
                'algorithm_info': data.get('algorithm_info', {}),
                'performance': {
                    'shot_count': data.get('shot_count', 0),
                    'processing_time': data.get('processing_time', 0),
                    'extracted_files': data.get('extracted_files', 0),
                    'success_rate': (data.get('extracted_files', 0) / max(data.get('shot_count', 1), 1) * 100)
                },
                'shots': []
            }

            # æ·»åŠ æ¯ä¸ªé•œå¤´çš„è¯¦ç»†ä¿¡æ¯
            if 'shots' in data:
                for i, shot in enumerate(data['shots']):
                    shot_info = {
                        'index': i + 1,
                        'start_frame': shot.start_frame,
                        'end_frame': shot.end_frame,
                        'start_time': shot.start_time,
                        'end_time': shot.end_time,
                        'duration': shot.duration,
                        'filename': f"shot_{i+1:02d}_{shot.to_time_string(shot.start_time)}_to_{shot.to_time_string(shot.end_time)}.mp4"
                    }
                    algo_data['shots'].append(shot_info)

            detailed_data['algorithms'][algorithm] = algo_data

        # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
        with open(self.detailed_report_path, 'w', encoding='utf-8') as jsonfile:
            json.dump(detailed_data, jsonfile, indent=2, ensure_ascii=False)

        print(f"âœ… è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {self.detailed_report_path}")

    def generate_summary_analysis(self, results: Dict[str, Dict[str, Any]]) -> str:
        """
        ç”Ÿæˆå¯¹æ¯”åˆ†ææ‘˜è¦

        Args:
            results: å„ç®—æ³•çš„ç»“æœæ•°æ®

        Returns:
            str: åˆ†ææ‘˜è¦æ–‡æœ¬
        """
        print("ğŸ” ç”Ÿæˆå¯¹æ¯”åˆ†ææ‘˜è¦...")

        summary_lines = [
            "=" * 60,
            "é•œå¤´åˆ†å‰²ç®—æ³•å¯¹æ¯”åˆ†ææ‘˜è¦",
            "=" * 60,
            f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            ""
        ]

        # ç»Ÿè®¡åŸºæœ¬ä¿¡æ¯
        total_shots = sum(data.get('shot_count', 0) for data in results.values())
        avg_processing_time = sum(data.get('processing_time', 0) for data in results.values()) / max(len(results), 1)

        summary_lines.extend([
            f"æ€»ä½“ç»Ÿè®¡:",
            f"  - æ€»æ£€æµ‹é•œå¤´æ•°: {total_shots}",
            f"  - å¹³å‡å¤„ç†æ—¶é—´: {avg_processing_time:.2f}ç§’",
            ""
        ])

        # å„ç®—æ³•è¯¦ç»†å¯¹æ¯”
        summary_lines.append("å„ç®—æ³•è¡¨ç°:")
        for algorithm, data in results.items():
            shot_count = data.get('shot_count', 0)
            processing_time = data.get('processing_time', 0)
            success_rate = (data.get('extracted_files', 0) / max(shot_count, 1) * 100)

            summary_lines.extend([
                f"  {algorithm}:",
                f"    - æ£€æµ‹é•œå¤´æ•°: {shot_count}",
                f"    - å¤„ç†æ—¶é—´: {processing_time:.2f}ç§’",
                f"    - æå–æˆåŠŸç‡: {success_rate:.1f}%"
            ])

        summary_lines.extend([
            "",
            "æ–‡ä»¶ä½ç½®:",
            f"  - è¾“å‡ºç›®å½•: {self.main_output_dir}",
            f"  - åŸºæœ¬æŠ¥å‘Š: {self.report_path}",
            f"  - è¯¦ç»†æŠ¥å‘Š: {self.detailed_report_path}",
            "=" * 60
        ])

        summary_text = "\n".join(summary_lines)

        # ä¿å­˜æ‘˜è¦åˆ°æ–‡ä»¶
        summary_path = os.path.join(self.main_output_dir, "analysis_summary.txt")
        with open(summary_path, 'w', encoding='utf-8') as f:
            f.write(summary_text)

        print(f"âœ… åˆ†ææ‘˜è¦å·²ä¿å­˜: {summary_path}")
        return summary_text

    def print_directory_structure(self):
        """æ‰“å°è¾“å‡ºç›®å½•ç»“æ„"""
        print("\nğŸ“‚ è¾“å‡ºç›®å½•ç»“æ„:")
        print(f"{self.main_output_dir}/")
        print("â”œâ”€â”€ pyscene/          # PySceneDetect ç»“æœ")
        print("â”œâ”€â”€ ffmpeg/           # FFmpeg ç»“æœ")
        print("â”œâ”€â”€ transnet/         # TransNet V2 ç»“æœ")
        print("â”œâ”€â”€ report.csv        # åŸºæœ¬å¯¹æ¯”æŠ¥å‘Š")
        print("â”œâ”€â”€ detailed_report.json  # è¯¦ç»†æŠ¥å‘Š")
        print("â””â”€â”€ analysis_summary.txt   # åˆ†ææ‘˜è¦")

    def get_output_info(self) -> Dict[str, str]:
        """
        è·å–è¾“å‡ºä¿¡æ¯

        Returns:
            Dict[str, str]: è¾“å‡ºè·¯å¾„ä¿¡æ¯
        """
        return {
            'main_output_dir': self.main_output_dir,
            'report_path': self.report_path,
            'detailed_report_path': self.detailed_report_path,
            'pyscene_dir': self.get_algorithm_output_dir('pyscene'),
            'ffmpeg_dir': self.get_algorithm_output_dir('ffmpeg'),
            'transnet_dir': self.get_algorithm_output_dir('transnet')
        }